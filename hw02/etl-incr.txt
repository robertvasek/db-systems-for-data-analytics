# Incremental ETL process

- Total time to insert new data in staging: 4.279 s

[ETL incremental script](etl-incr.sql)


- Comment on the ideas/steps used in the implementation:

1. Dimension Date Handling: 
- we noticed that the dates for april 2025 were missing in the dimension.
- we wrote a query to select unique dates from the new tracking data and insert them into dim_date,
    but only if they didn't exist yet. this was necessary to make sure the foreign keys wouldn't fail during the fact load.

2. Automatic SCD Type 2 Updates for Cars:
- we handled the changes to car details in two steps.
- first, we 'closed' the old records by updating their valid_to date to '2025-04-01'
    and setting them to inactive, but only for cars where the data actually changed (we used 'is distinct from' to check this).
- second, we inserted the new versions of these cars starting from april 1st with a valid_to of 'infinity'.
- this keeps the history intact while showing the new current state.

3. Fact Table Loading with Temporal Join:
- when loading the tracking facts, we couldn't just join on the car key because of the history changes.
- we used a temporal join where we checked if the tracking time fell between the car's valid_from and valid_to dates.
- this ensures each trip is linked to the correct version of the car (like the correct license plate) at that specific moment.
- we also added 'distinct on' to handle some duplicate timestamps in the source data that were causing primary key errors.